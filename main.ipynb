{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpringlesinghal\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile\n",
    "\n",
    "from data_preprocess import *\n",
    "from model import NN\n",
    "from dshap import *\n",
    "from utilities import *\n",
    "from fl_methods import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "wandb_config = {}\n",
    "\n",
    "random_seed = 0 # log with wandb\n",
    "wandb_config['random_seed'] = random_seed\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files already downloaded\n"
     ]
    }
   ],
   "source": [
    "train_data_global, val_data_global, test_data_global = load_mnist()\n",
    "input_dim = 784\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 20 # log with wandb\n",
    "alpha = 1e6 # log with wandb\n",
    "wandb_config['num_clients'] = num_clients\n",
    "wandb_config['alpha'] = alpha\n",
    "client_indices = NIIDClientSplit(train_data=train_data_global, num_clients=num_clients, alpha=alpha)\n",
    "client_indices_batched = DivideIntoBatches(client_indices, num_batches = 10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute shapley value for all minibatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 0...........\n"
     ]
    }
   ],
   "source": [
    "dshap = {i:None for i in range(num_clients)}\n",
    "for i in range(num_clients):\n",
    "  print(f\"Starting {i}...........\")\n",
    "  dshap[i] = DShapMiniBatches(client_indices_batched[i], client_indices[i], train_data_global)\n",
    "\n",
    "for i in range(num_clients):\n",
    "  dshaplist = []\n",
    "  for j in range(Nb):\n",
    "    dshaplist.append(dshap[i][j])\n",
    "  dshap[i] = dshaplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.NN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['random','server-selection','client-sampling','client-transmission']\n",
    "initModel = NN(input_dim = input_dim, output_dim = output_dim) # use the same model for all experiments\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise test data\n",
    "test_data = test_data_global.data.to(device = device)\n",
    "test_targets = test_data_global.targets.to(device = device)\n",
    "\n",
    "learning_rate = 0.001 # can try hyperparameter sweep with wandb\n",
    "wandb_config['learning_rate'] = learning_rate\n",
    "num_communication_rounds = 400 \n",
    "wandb_config['num_communication_rounds'] = num_communication_rounds\n",
    "server_select_fraction = 0.1\n",
    "wandb_config['server_select_fraction'] = server_select_fraction\n",
    "client_iterations = 1 # >1 for FedAvg, 1 for FedSGD\n",
    "wandb_config['client_iterations'] = client_iterations\n",
    "\n",
    "loss_lists = []\n",
    "accuracy_lists = []\n",
    "avg_active_clients_list = []\n",
    "\n",
    "for experiment in experiments:\n",
    "  config = deepcopy(wandb_config)\n",
    "  config['experiment'] = experiment\n",
    "\n",
    "  server_selection = \"random\" # or \"shapley\"\n",
    "  client_sampling = \"random\" # or \"shapley\"\n",
    "  client_transmission = \"always\" # or \"shapley\"\n",
    "\n",
    "  if experiment == 'server-selection':\n",
    "    # shapley based server selection is compared with random selection\n",
    "    server_selection = \"shapley\"\n",
    "  elif experiment == 'client-sampling':\n",
    "    # shapley based importance sampling is compared with random sampling\n",
    "    client_sampling = \"shapley\"\n",
    "  elif experiment == 'client-transmission':\n",
    "    # shapley based thresholding is compared with transmitting always\n",
    "    shapley_threshold = 0.5\n",
    "    config['shapley_threshold'] = shapley_threshold\n",
    "    client_transmission = \"shapley\"\n",
    "\n",
    "  config['server_selection'] = server_selection\n",
    "  config['client_sampling'] = client_sampling\n",
    "  config['client_transmission'] = client_transmission\n",
    "\n",
    "  wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"shapley-fl\", \n",
    "    # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
    "    name=f\"{experiment}-1\",  \n",
    "    # Track hyperparameters and run metadata\n",
    "    config=config)\n",
    "\n",
    "  # initialise server model and compute initial accuracy and loss\n",
    "  serverModel = deepcopy(initModel).to(device)\n",
    "  serverOptimiser = optim.Adam(serverModel.parameters(), lr = learning_rate)\n",
    "\n",
    "  loss, accuracy = model_accuracy(serverModel, test_data, test_targets, criterion, device)\n",
    "\n",
    "  loss_list = [loss]\n",
    "  accuracy_list = [accuracy]  \n",
    "  avg_active_clients = 0\n",
    "\n",
    "  if server_selection == \"shapley\":\n",
    "    client_values = [0 for i in range(num_clients)]\n",
    "\n",
    "\n",
    "  for communication_round in tqdm(range(num_communication_rounds)):\n",
    "    '''\n",
    "    At server:\n",
    "    - select clients to communicate with\n",
    "    - two schemes: random selection, GTG-Shapley\n",
    "    '''\n",
    "    if communication_round < 3*(1/server_select_fraction) or server_selection == \"random\":\n",
    "      # random client selection\n",
    "      num_selected = int(server_select_fraction*num_clients)\n",
    "      selected_clients = [(i < num_selected) for i in range(num_clients)]\n",
    "      np.random.shuffle(selected_clients)\n",
    "    elif server_selection == \"shapley\":\n",
    "      # GTG-Shapley client selection\n",
    "      num_selected = int(server_select_fraction*num_clients)\n",
    "      all_clients = list(range(num_clients))\n",
    "      selected_indices = np.argpartition(client_values, -1*num_selected)[-1*num_selected:]\n",
    "      selected_clients = [False for i in range(num_clients)]\n",
    "      for i in selected_indices:\n",
    "        selected_clients[i] = True\n",
    "\n",
    "    client_gradients = []\n",
    "    sent_status = []\n",
    "\n",
    "    for i in range(num_clients):\n",
    "      if selected_clients[i]:\n",
    "        # set client model weights to aggregator weights, and copy optimiser state\n",
    "        clientModel = NN(input_dim = input_dim, output_dim = output_dim)\n",
    "        clientModel = clientModel.to(device)\n",
    "        clientModel.load_state_dict(serverModel.state_dict())\n",
    "        clientOptimiser = optim.SGD(clientModel.parameters(), lr = learning_rate)\n",
    "        clientOptimiser.zero_grad()\n",
    "        dshap_chosen = 0\n",
    "        for iteration in range(client_iterations):\n",
    "          # select client minibatch\n",
    "          if client_sampling == \"random\":\n",
    "            # choose the minibatch for client i randomly\n",
    "            # minibatch_idx\n",
    "            vals = list(range(len(client_indices_batched[i]))) # list of minibatches (len = # minibatches)\n",
    "            minibatch_idx = np.random.choice(vals, size = 1)[0] # draw a random minibatch k\n",
    "          elif client_sampling == \"shapley\":\n",
    "            # choose the minibatch for client i with importance sampling\n",
    "            # minibatch_idx\n",
    "            wts = np.array(dshap[i]) # weights for importance sampling\n",
    "            wts = np.array([max(i, 1e-7) for i in wts])\n",
    "            # negative dshap minibatches are never chosen, need to add some error handling\n",
    "            vals = list(range(len(dshap[i]))) # list of minibatches (len = # minibatches)\n",
    "            wtsum = np.sum(wts)\n",
    "            wts = wts/wtsum # TODO: add error handling for case when all minibatches are bad and wtsum = 0\n",
    "            minibatch_idx = np.random.choice(vals, size = 1, p = wts)[0] # draw a random minibatch k\n",
    "            dshap_chosen += dshap[i][minibatch_idx]\n",
    "          \n",
    "            # update gradients on this chosen client minibatch\n",
    "            data_raw_minibatch = [train_data_global.data[j] for j in client_indices_batched[i][minibatch_idx]]\n",
    "            targets_raw_minibatch = [int(train_data_global.targets[j]) for j in client_indices_batched[i][minibatch_idx]]\n",
    "            data_minibatch = torch.stack(data_raw_minibatch,0).to(device=device).to(torch.float32)\n",
    "            targets_minibatch = torch.tensor(targets_raw_minibatch).to(device=device)\n",
    "\n",
    "            scores = clientModel(data_minibatch)\n",
    "            loss = criterion(scores, targets_minibatch)\n",
    "            loss.backward()\n",
    "            clientOptimiser.step()\n",
    "        \n",
    "        dshap_chosen /= client_iterations\n",
    "        # compute client gradients\n",
    "        if client_transmission == \"always\":\n",
    "          sent_status.append(True)\n",
    "        elif client_transmission == \"shapley\":\n",
    "          sent_status.append(True if dshap_chosen > shapley_threshold else False)\n",
    "\n",
    "        if sent_status[-1] == True: \n",
    "          client_gradients.append(clientModel.gradients())\n",
    "        else:\n",
    "          client_gradients.append(None)\n",
    "\n",
    "      else:\n",
    "        # if the client is not selected\n",
    "        sent_status.append(False)\n",
    "        client_gradients.append(None)\n",
    "    # end gradient collection loop \n",
    "    avg_active_clients = ((communication_round)*avg_active_clients + np.sum(sent_status))/(communication_round + 1)\n",
    "\n",
    "    print_results = False\n",
    "    if communication_round % 10 == 0:\n",
    "      print_results = True\n",
    "    # combine gradients and take a step at aggregator and update aggregator weights\n",
    "    if server_selection == \"random\":\n",
    "      aggregator_update(client_gradients, sent_status, model=serverModel, optimiser=serverOptimiser)\n",
    "    elif server_selection == \"shapley\":\n",
    "      client_values = aggregator_update_shapley(client_values, client_gradients, sent_status, model=serverModel, optimiser=serverOptimiser, val_data = val_data_global, criterion = criterion, device = device)\n",
    "\n",
    "    loss, accuracy = model_accuracy(serverModel, test_data, test_targets, criterion)\n",
    "    loss_list.append(loss)\n",
    "    accuracy_list.append(accuracy)\n",
    "    wandb.log({'loss': loss, 'accuracy': accuracy, 'average_active_clients': avg_active_clients})\n",
    "    wandb.log({f'client_values_{i}':client_values[i] for i in range(num_clients)})\n",
    "    if print_results == True:\n",
    "      print(f\"loss = {loss:.4f}, accuracy = {accuracy*100:.3f}\")\n",
    "\n",
    "  print(f\"avg_active_clients = {avg_active_clients}\")\n",
    "\n",
    "  loss_lists.append(loss_list)\n",
    "  accuracy_lists.append(accuracy_list)\n",
    "  avg_active_clients_list.append(avg_active_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([1,2,3]) - set([1,2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "niid-bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
