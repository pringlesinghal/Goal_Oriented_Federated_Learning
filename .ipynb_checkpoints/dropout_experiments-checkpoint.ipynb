{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "# %mkdir gdrive/MyDrive/AAU_Project\n",
    "%cd gdrive/MyDrive/AAU_Project\n",
    "# !git clone https://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@github.com/pringlesinghal/Goal_Oriented_Federated_Learning.git\n",
    "%cd Goal_Oriented_Federated_Learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:56<00:00,  4.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from itertools import chain, combinations\n",
    "from math import comb\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from data_preprocess import (\n",
    "    load_mnist_flat,\n",
    "    load_cifar10,\n",
    "    NIIDClientSplit,\n",
    "    synthetic_samples,\n",
    ")\n",
    "from model import NN, CNN\n",
    "from dshap import convergenceTest\n",
    "\n",
    "os.makedirs(\"./processed_data/mnist/\", exist_ok=True)\n",
    "os.makedirs(\"./processed_data/cifar10/\", exist_ok=True)\n",
    "os.makedirs(\"./processed_data/mnist_flat/\", exist_ok=True)\n",
    "os.makedirs(\"./processed_data/cifar10_flat/\", exist_ok=True)\n",
    "\n",
    "# global variables\n",
    "wandb_config = {}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"meta\"\n",
    "wandb_config[\"device\"] = device\n",
    "\n",
    "\n",
    "class Client:\n",
    "    def __init__(self, data, targets, device):\n",
    "        self.data = data.to(device)\n",
    "        self.targets = targets.to(device)\n",
    "        self.device = device\n",
    "        self.length = len(self.data)\n",
    "\n",
    "    def train(self, serverModel, criterion, E, B, learning_rate, momentum):\n",
    "        \"\"\"\n",
    "        serverModel - server model\n",
    "        criterion - loss function (model, data, targets)\n",
    "        E - number of epochs\n",
    "        B - number of batches\n",
    "\n",
    "        returns clientModel.state_dict() after training\n",
    "        \"\"\"\n",
    "        clientModel = deepcopy(serverModel)\n",
    "        clientModel = clientModel.to(self.device)\n",
    "        clientModel.load_state_dict(serverModel.state_dict())\n",
    "        clientOptimiser = optim.SGD(\n",
    "            clientModel.parameters(), lr=learning_rate, momentum=momentum\n",
    "        )\n",
    "\n",
    "        batch_indices = self.split_indices(B)\n",
    "\n",
    "        for epoch in range(E):\n",
    "            for batch in range(B):\n",
    "                data_batch, targets_batch = self.get_subset(batch_indices[batch])\n",
    "                clientOptimiser.zero_grad()\n",
    "                loss = criterion(clientModel, data_batch, targets_batch)\n",
    "                loss.backward()\n",
    "                clientOptimiser.step()\n",
    "\n",
    "        self.model = clientModel\n",
    "        return clientModel.state_dict()\n",
    "\n",
    "    def loss(self, model, criterion):\n",
    "        \"\"\"\n",
    "        criterion - loss function (model, data, targets)\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = criterion(model, self.data, self.targets)\n",
    "        model.train()\n",
    "        return float(loss.cpu())\n",
    "\n",
    "    def accuracy(self):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            scores = self.model(self.data)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct = torch.sum(predictions == self.targets)\n",
    "            total = self.length\n",
    "            accuracy = num_correct / total\n",
    "        self.model.train()\n",
    "        return float(accuracy.cpu())\n",
    "\n",
    "    def get_subset(self, indices):\n",
    "        \"\"\"\n",
    "        return a subset of client data and targets with the given indices\n",
    "        \"\"\"\n",
    "        data_raw = [self.data[j] for j in indices]\n",
    "        targets_raw = [int(self.targets[j]) for j in indices]\n",
    "        # prepare data and targets for training\n",
    "        data = torch.stack(data_raw, 0).to(device=self.device).to(torch.float32)\n",
    "        targets = torch.tensor(targets_raw).to(device=self.device)\n",
    "        return data, targets\n",
    "\n",
    "    def split_indices(self, B):\n",
    "        \"\"\"\n",
    "        return a list of indices for B batches\n",
    "        \"\"\"\n",
    "        length = self.length\n",
    "        indices = list(range(length))\n",
    "        np.random.shuffle(indices)\n",
    "        k = int(np.floor(length / B))\n",
    "        # drops the last few datapoints, if needed, to keep batch size fixed\n",
    "        return [indices[i : i + k] for i in range(0, len(indices), k)]\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, model, val_data, val_targets, test_data, test_targets, device):\n",
    "        self.model = deepcopy(model).to(device)\n",
    "        self.val_data = val_data.to(device=device)\n",
    "        self.val_targets = val_targets.to(device=device)\n",
    "        self.test_data = test_data.to(device=device)\n",
    "        self.test_targets = test_targets.to(device=device)\n",
    "        self.length = len(test_data)\n",
    "        self.device = device\n",
    "\n",
    "    def aggregate(self, client_states, weights=None):\n",
    "        \"\"\"\n",
    "        client_states - list of client states\n",
    "        weights - weights for averaging (uniform by default)\n",
    "\n",
    "        updates server model by performing weighted averaging\n",
    "        \"\"\"\n",
    "        model = self.aggregate_(client_states, weights)\n",
    "        self.model.load_state_dict(model.state_dict())\n",
    "\n",
    "    def aggregate_(self, client_states, weights=None):\n",
    "        \"\"\"\n",
    "        does not modify the server model\n",
    "        only returns the updated model\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            # uniform weights by default\n",
    "            weights = [1 / len(client_states)] * len(client_states)\n",
    "        weights = np.array(weights)\n",
    "        wtsum = np.sum(weights)\n",
    "        weights = weights / wtsum  # normalize weights\n",
    "        # initialise model parameters to zero\n",
    "        model_state = self.model.state_dict()\n",
    "        for key in model_state.keys():\n",
    "            model_state[key] -= model_state[key]\n",
    "        # find updated model - weighted averaging\n",
    "        for idx, client_state in enumerate(client_states):\n",
    "            for key in model_state.keys():\n",
    "                model_state[key] += weights[idx] * client_state[key]\n",
    "        model = deepcopy(self.model).to(device=self.device)\n",
    "        model.load_state_dict(model_state)\n",
    "        return model\n",
    "\n",
    "    def shapley_values_mc(self, criterion, client_states, weights=None):\n",
    "        \"\"\"\n",
    "        client_states - list of client states\n",
    "        weights - weights for averaging (uniform by default)\n",
    "\n",
    "        computes shapley values for the client updates on validation dataset\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            # uniform weights by default\n",
    "            weights = [1 / len(client_states)] * len(client_states)\n",
    "        weights = np.array(weights)\n",
    "        wtsum = np.sum(weights)\n",
    "        weights = weights / wtsum  # normalize weights\n",
    "\n",
    "        num_clients = len(client_states)\n",
    "        T = 50\n",
    "\n",
    "        shapley_values = [[0] for i in range(num_clients)]\n",
    "\n",
    "        for idx in range(num_clients):\n",
    "            # compute shapley value of idx client\n",
    "            \"\"\"\n",
    "            until convergence:\n",
    "                sample a subset size k\n",
    "                sample subset of size k of clients (except idx)\n",
    "                compute updated model with this subset of clients\n",
    "                compute loss of updated model on validation set\n",
    "                compute another updated model with the idx client included\n",
    "                compute loss of updated model on validation set\n",
    "                compute difference between losses of the two models\n",
    "                average losses over subsets to compute the shapley value of idx client\n",
    "            \"\"\"\n",
    "            t = 0\n",
    "            remaining_clients = [i for i in range(num_clients) if i != idx]\n",
    "            while t < T:\n",
    "                subset_size = np.random.choice(list(range(num_clients - 1)), size=1)[0]\n",
    "                subset = np.random.choice(\n",
    "                    remaining_clients, size=subset_size, replace=False\n",
    "                )\n",
    "                client_states_subset = [client_states[i] for i in subset]\n",
    "                weights_subset = [weights[i] for i in subset]\n",
    "                model_subset = self.aggregate_(client_states_subset, weights_subset)\n",
    "                loss_subset = self.val_loss(model_subset, criterion)\n",
    "\n",
    "                client_states_subset.append(client_states[idx])\n",
    "                weights_subset.append(weights[idx])\n",
    "                model_subset_with_idx = self.aggregate_(\n",
    "                    client_states_subset, weights_subset\n",
    "                )\n",
    "                loss_subset_with_idx = self.val_loss(model_subset_with_idx, criterion)\n",
    "\n",
    "                loss_diff = loss_subset - loss_subset_with_idx\n",
    "                prev_avg = shapley_values[idx][-1]\n",
    "                new_avg = (t * prev_avg + loss_diff) / (t + 1)\n",
    "                shapley_values[idx].append(new_avg)\n",
    "                if convergenceTest(shapley_values[idx]):\n",
    "                    break\n",
    "                t += 1\n",
    "        final_shapley_values = [shapley_values[i][-1] for i in range(num_clients)]\n",
    "        return final_shapley_values\n",
    "\n",
    "    def shapley_values_tmc(self, criterion, client_states, weights=None):\n",
    "        \"\"\"\n",
    "        client_states - list of client states\n",
    "        weights - weights for averaging (uniform by default)\n",
    "\n",
    "        computes shapley values for the client updates on validation dataset\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            # uniform weights by default\n",
    "            weights = [1 / len(client_states)] * len(client_states)\n",
    "        weights = np.array(weights)\n",
    "        wtsum = np.sum(weights)\n",
    "        weights = weights / wtsum  # normalize weights\n",
    "\n",
    "        num_clients = len(client_states)\n",
    "\n",
    "        shapley_values = [[0] for i in range(num_clients)]\n",
    "        converged = False\n",
    "\n",
    "        T = 50 * num_clients\n",
    "        t = 0\n",
    "        threshold = 1e-5\n",
    "        v_init = self.val_loss(self.model, criterion)  # initial server model loss\n",
    "        model_final = self.aggregate_(client_states, weights)\n",
    "        v_final = self.val_loss(model_final, criterion)  # final server model loss\n",
    "        while not converged and (t < T):\n",
    "            t += 1\n",
    "            client_permutation = np.random.permutation(num_clients)\n",
    "            v_j = v_init\n",
    "            for j in range(num_clients):\n",
    "                if np.abs(v_final - v_j) < threshold:\n",
    "                    v_jplus1 = v_j\n",
    "                else:\n",
    "                    subset = client_permutation[: (j + 1)]\n",
    "                    client_states_subset = [client_states[i] for i in subset]\n",
    "                    weights_subset = [weights[i] for i in subset]\n",
    "                    model_subset = self.aggregate_(client_states_subset, weights_subset)\n",
    "                    v_jplus1 = self.val_loss(model_subset, criterion)\n",
    "\n",
    "                phi_old = shapley_values[client_permutation[j]][-1]\n",
    "                phi_new = ((t - 1) * phi_old + (v_jplus1 - v_j)) / t\n",
    "                shapley_values[client_permutation[j]].append(phi_new)\n",
    "\n",
    "            flag = True\n",
    "            for j in range(num_clients):\n",
    "                if not convergenceTest(shapley_values):\n",
    "                    flag = False\n",
    "            if flag:\n",
    "                converged = True\n",
    "\n",
    "        final_shapley_values = [shapley_values[i][-1] for i in range(num_clients)]\n",
    "        return final_shapley_values\n",
    "\n",
    "    def shapley_values_true(self, criterion, client_states, weights=None):\n",
    "        \"\"\"\n",
    "        client_states - list of client states\n",
    "        weights - weights for averaging (uniform by default)\n",
    "\n",
    "        computes shapley values for the client updates on validation dataset\n",
    "        \"\"\"\n",
    "\n",
    "        def powerset(iterable):\n",
    "            \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "            s = list(iterable)\n",
    "            return list(\n",
    "                chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))\n",
    "            )\n",
    "\n",
    "        if weights is None:\n",
    "            # uniform weights by default\n",
    "            weights = [1 / len(client_states)] * len(client_states)\n",
    "        weights = np.array(weights)\n",
    "        wtsum = np.sum(weights)\n",
    "        weights = weights / wtsum  # normalize weights\n",
    "\n",
    "        num_clients = len(client_states)\n",
    "        client_subsets = powerset(range(num_clients))\n",
    "        subset_losses = {i: 0 for i in client_subsets}\n",
    "        shapley_values = [[0] for i in range(num_clients)]\n",
    "\n",
    "        for subset in client_subsets:\n",
    "            client_states_subset = [client_states[i] for i in subset]\n",
    "            weights_subset = [weights[i] for i in subset]\n",
    "            model_subset = self.aggregate_(client_states_subset, weights_subset)\n",
    "            loss_subset = self.val_loss(model_subset, criterion)\n",
    "            subset_losses[subset] = loss_subset\n",
    "\n",
    "        for subset in client_subsets:\n",
    "            for idx in range(num_clients):\n",
    "                L = len(subset)  # subset size\n",
    "                if idx in subset:\n",
    "                    nck = comb(num_clients - 1, L - 1)\n",
    "                    prev_val = shapley_values[idx][-1]\n",
    "                    new_val = prev_val + subset_losses[subset] / nck\n",
    "                    shapley_values[idx].append(new_val)\n",
    "                else:\n",
    "                    nck = comb(num_clients - 1, L)\n",
    "                    prev_val = shapley_values[idx][-1]\n",
    "                    new_val = prev_val - subset_losses[subset] / nck\n",
    "                    shapley_values[idx].append(new_val)\n",
    "\n",
    "        final_shapley_values = [shapley_values[i][-1] for i in range(num_clients)]\n",
    "        return final_shapley_values\n",
    "\n",
    "    def test_loss(self, criterion):\n",
    "        \"\"\"\n",
    "        criterion - loss function (model, data, targets)\n",
    "\n",
    "        computes loss on test set with the server model\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = criterion(self.model, self.test_data, self.test_targets)\n",
    "        self.model.train()\n",
    "        return float(loss.cpu())\n",
    "\n",
    "    def accuracy(self):\n",
    "        \"\"\"\n",
    "        test accuracy\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            scores = self.model(self.test_data)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct = torch.sum(predictions == self.test_targets)\n",
    "            total = self.length\n",
    "            accuracy = num_correct / total\n",
    "        self.model.train()\n",
    "        return float(accuracy.cpu())\n",
    "\n",
    "    def val_loss(self, model, criterion):\n",
    "        \"\"\"\n",
    "        model\n",
    "        criterion - loss function (model, data, targets)\n",
    "\n",
    "        computes loss on validation set with the given model\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = criterion(model, self.val_data, self.val_targets)\n",
    "        model.train()\n",
    "        return float(loss.cpu())\n",
    "\n",
    "\n",
    "# data, models\n",
    "\"\"\"\n",
    "1. Synthetic(alpha, beta) - Logistic Regression\n",
    "    num_clients = 30\n",
    "    number of data points distributed by power law\n",
    "    \n",
    "2. MNIST - MLP\n",
    "\n",
    "3. CIFAR10 - CNN\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def initNetworkData(dataset, num_clients, random_seed, alpha, beta=0):\n",
    "    \"\"\"\n",
    "    choose dataset from [\"synthetic\", \"mnist\", \"cifar10\"]\n",
    "    num_clients - number of clients\n",
    "    random_seed - random seed\n",
    "    alpha - Dirichlet parameter (for mnist, cifar10) / Variance (for synthetic)\n",
    "    beta - Variance parameter (for synthetic only, not needed for mnist, cifar10)\n",
    "    \"\"\"\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    if dataset not in [\"synthetic\", \"mnist\", \"cifar10\"]:\n",
    "        raise Exception(\"Invalid dataset\")\n",
    "\n",
    "    elif dataset == \"synthetic\":\n",
    "        clients = []\n",
    "        test_val_data = []\n",
    "        test_val_targets = []\n",
    "\n",
    "        # distribute data points to num_clients clients by the power law\n",
    "        client_datapoint_fractions = np.random.uniform(0, 1, num_clients) ** (\n",
    "            1 / 3\n",
    "        )  # inverse CDF sampling\n",
    "        client_datapoint_fractions = client_datapoint_fractions / np.sum(\n",
    "            client_datapoint_fractions\n",
    "        )\n",
    "        total_train_datapoints = 60000\n",
    "        num_datapoints = total_train_datapoints * client_datapoint_fractions\n",
    "        for i in range(num_clients):\n",
    "            N_i = int(num_datapoints[i])\n",
    "            train_i, test_val_i = synthetic_samples(alpha, beta, N_i)\n",
    "            clients.append(Client(train_i[\"data\"], train_i[\"targets\"], device))\n",
    "            test_val_data.extend(test_val_i[\"data\"])\n",
    "            test_val_targets.extend(test_val_i[\"targets\"])\n",
    "\n",
    "        serverModel = nn.Sequential(nn.Linear(60, 10))\n",
    "        # compute total number of datapoints in test_val_data\n",
    "        test_val_length = len(test_val_data)\n",
    "        # split these 50:50 between test and val sets\n",
    "        test_val_indices = list(range(test_val_length))\n",
    "        np.random.shuffle(test_val_indices)\n",
    "        test_indices = test_val_indices[: int(test_val_length / 2)]\n",
    "        val_indices = test_val_indices[int(test_val_length / 2) :]\n",
    "        test_val_data = torch.stack(test_val_data)\n",
    "        test_val_targets = torch.stack(test_val_targets)\n",
    "        val_data = test_val_data[val_indices]\n",
    "        val_targets = test_val_targets[val_indices]\n",
    "        test_data = test_val_data[test_indices]\n",
    "        test_targets = test_val_targets[test_indices]\n",
    "        server = Server(\n",
    "            serverModel, val_data, val_targets, test_data, test_targets, device\n",
    "        )\n",
    "\n",
    "    elif dataset == \"mnist\":\n",
    "        train_dataset, val_dataset, test_dataset = load_mnist_flat()\n",
    "        client_indices = NIIDClientSplit(train_dataset, num_clients, alpha)\n",
    "        clients = []\n",
    "        for i in range(num_clients):\n",
    "            clients.append(\n",
    "                Client(\n",
    "                    train_dataset.data[client_indices[i]],\n",
    "                    train_dataset.targets[client_indices[i]],\n",
    "                    device,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        serverModel = NN(input_dim=784, output_dim=10)\n",
    "        server = Server(\n",
    "            serverModel,\n",
    "            val_dataset.data,\n",
    "            val_dataset.targets,\n",
    "            test_dataset.data,\n",
    "            test_dataset.targets,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "    elif dataset == \"cifar10\":\n",
    "        train_dataset, val_dataset, test_dataset = load_cifar10()\n",
    "        client_indices = NIIDClientSplit(train_dataset, num_clients, alpha)\n",
    "        clients = []\n",
    "        for i in range(num_clients):\n",
    "            clients.append(\n",
    "                Client(\n",
    "                    train_dataset.data[client_indices[i]],\n",
    "                    train_dataset.targets[client_indices[i]],\n",
    "                    device,\n",
    "                )\n",
    "            )\n",
    "        in_channels = 3\n",
    "        output_dim = 10\n",
    "        input_h = 32\n",
    "        input_w = 32\n",
    "        serverModel = CNN(in_channels, input_w, input_h, output_dim)\n",
    "        server = Server(\n",
    "            serverModel,\n",
    "            val_dataset.data,\n",
    "            val_dataset.targets,\n",
    "            test_dataset.data,\n",
    "            test_dataset.targets,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "    return clients, server\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "main code starts here\n",
    "\"\"\"\n",
    "\n",
    "# CONFIGURE\n",
    "\n",
    "# generate/load data and distribute across clients and server\n",
    "# datasets = [\"cifar10\", \"mnist\", \"synthetic\"]\n",
    "\n",
    "dataset = \"synthetic\"\n",
    "num_clients = 20\n",
    "random_seed = 2\n",
    "alpha = 0.5\n",
    "beta = 0.5  # needed for synthetic dataset\n",
    "\n",
    "clients, server = initNetworkData(dataset, num_clients, random_seed, alpha, beta)\n",
    "wandb_config[\"dataset\"] = dataset\n",
    "wandb_config[\"num_clients\"] = num_clients\n",
    "wandb_config[\"alpha\"] = alpha\n",
    "wandb_config[\"beta\"] = beta\n",
    "wandb_config[\"clients\"] = clients\n",
    "wandb_config[\"server\"] = server\n",
    "\n",
    "T = 100  # number of communications rounds\n",
    "select_fraction = 0.1\n",
    "wandb_config[\"num_communication_rounds\"] = T\n",
    "wandb_config[\"select_fraction\"] = select_fraction\n",
    "random_seed = 1\n",
    "\n",
    "\n",
    "# both may be same/different\n",
    "## define a criterion for client optimisation\n",
    "## define a criterion for server evaluation\n",
    "\n",
    "\n",
    "def fed_prox_criterion(model_reference, mu):\n",
    "    \"\"\"\n",
    "    returns the required function when called\n",
    "    loss function for FedProx with chosen mu parameter\n",
    "    \"\"\"\n",
    "    model_reference = deepcopy(model_reference)\n",
    "\n",
    "    def loss(model, data, targets):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        scores = model(data)\n",
    "        loss_value = criterion(scores, targets)\n",
    "        for param, param_reference in zip(\n",
    "            model.parameters(), model_reference.parameters()\n",
    "        ):\n",
    "            loss_value += 0.5 * mu * (param - param_reference).norm(2)\n",
    "        return loss_value\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def fed_avg_criterion():\n",
    "    def loss(model, data, targets):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        scores = model(data)\n",
    "        return criterion(scores, targets)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def topk(values, k):\n",
    "    # returns indices of top-k values with ties broken at random\n",
    "    values = np.array(values)\n",
    "    p = np.random.permutation(len(values))\n",
    "    indices = p[np.argpartition(values[p], -k)[-k:]]\n",
    "    return indices\n",
    "\n",
    "\n",
    "def fed_avg_run(\n",
    "    clients,\n",
    "    server,\n",
    "    select_fraction,\n",
    "    T,\n",
    "    random_seed=0,\n",
    "    E=5,\n",
    "    B=10,\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.5,\n",
    "):\n",
    "    config = deepcopy(wandb_config)\n",
    "    config[\"algorithm\"] = \"FedAvg\"\n",
    "    wandb.init(project=\"federated-learning-summary\", config=config)\n",
    "    clients = deepcopy(clients)\n",
    "    server = deepcopy(server)\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    num_clients = len(clients)\n",
    "    num_selected = int(np.ceil(select_fraction * num_clients))\n",
    "\n",
    "    accuracy = []\n",
    "    val_loss = []\n",
    "    test_loss = []\n",
    "    for t in tqdm(range(T)):\n",
    "        # select clients to transmit weights to\n",
    "\n",
    "        # uniform random\n",
    "        all_clients = [i for i in range(num_clients)]\n",
    "        np.random.shuffle(all_clients)\n",
    "        selected_client_indices = all_clients[0:num_selected]\n",
    "        selected_status = [False for i in range(num_clients)]\n",
    "        for i in range(num_clients):\n",
    "            if i in selected_client_indices:\n",
    "                selected_status[i] = True\n",
    "\n",
    "        client_states = []\n",
    "        weights = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            if selected_status[idx]:\n",
    "                # perform descent at client\n",
    "                client_state = client.train(\n",
    "                    server.model,\n",
    "                    criterion=fed_avg_criterion(),\n",
    "                    E=E,\n",
    "                    B=B,\n",
    "                    learning_rate=learning_rate,\n",
    "                    momentum=momentum,\n",
    "                )\n",
    "                weight = client.length  # number of data points at client\n",
    "                client_states.append(client_state)\n",
    "                weights.append(weight)\n",
    "\n",
    "        server.aggregate(client_states, weights)\n",
    "        accuracy_now = server.accuracy()\n",
    "        val_loss_now = server.val_loss(server.model, fed_avg_criterion())\n",
    "        test_loss_now = server.test_loss(fed_avg_criterion())\n",
    "        accuracy.append(accuracy_now)\n",
    "        val_loss.append(val_loss_now)\n",
    "        test_loss.append(test_loss_now)\n",
    "\n",
    "        log_dict = {\n",
    "            \"accuracy\": accuracy_now,\n",
    "            \"val_loss\": val_loss_now,\n",
    "            \"test_loss\": test_loss_now,\n",
    "        }\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    wandb.finish()\n",
    "    return accuracy, val_loss, test_loss\n",
    "\n",
    "\n",
    "def fed_avg_run_analysis(\n",
    "    clients,\n",
    "    server,\n",
    "    select_fraction,\n",
    "    T,\n",
    "    random_seed=0,\n",
    "    E=5,\n",
    "    B=10,\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.5,\n",
    "):\n",
    "    # config = deepcopy(wandb_config)\n",
    "    # config[\"algorithm\"] = \"FedAvg\"\n",
    "    # wandb.init(project=\"federated-learning-summary\", config=config)\n",
    "    clients = deepcopy(clients)\n",
    "    server = deepcopy(server)\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    num_clients = len(clients)\n",
    "    num_selected = int(np.ceil(select_fraction * num_clients))\n",
    "\n",
    "    accuracy = []\n",
    "    val_loss = []\n",
    "    test_loss = []\n",
    "    client_losses_init = {i: [] for i in range(num_clients)}\n",
    "    client_losses_final = {i: [] for i in range(num_clients)}\n",
    "    for t in tqdm(range(T)):\n",
    "        # select clients to transmit weights to\n",
    "\n",
    "        # uniform random\n",
    "        all_clients = [i for i in range(num_clients)]\n",
    "        np.random.shuffle(all_clients)\n",
    "        selected_client_indices = all_clients[0:num_selected]\n",
    "        selected_status = [False for i in range(num_clients)]\n",
    "        for i in range(num_clients):\n",
    "            if i in selected_client_indices:\n",
    "                selected_status[i] = True\n",
    "\n",
    "        client_states = []\n",
    "        weights = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            client_losses_init[idx].append(\n",
    "                client.loss(server.model, fed_avg_criterion())\n",
    "            )\n",
    "            # if selected_status[idx]:\n",
    "            # perform descent at client\n",
    "            client_state = client.train(\n",
    "                server.model,\n",
    "                criterion=fed_avg_criterion(),\n",
    "                E=E,\n",
    "                B=B,\n",
    "                learning_rate=learning_rate,\n",
    "                momentum=momentum,\n",
    "            )\n",
    "            weight = client.length  # number of data points at client\n",
    "            client_states.append(client_state)\n",
    "            weights.append(weight)\n",
    "            client_losses_final[idx].append(\n",
    "                client.loss(client.model, fed_avg_criterion())\n",
    "            )\n",
    "\n",
    "        client_states_subset = []\n",
    "        weights_subset = []\n",
    "        for idx in range(num_clients):\n",
    "            if selected_status[idx]:\n",
    "                client_states_subset.append(client_states[idx])\n",
    "                weights_subset.append(weights[idx])\n",
    "\n",
    "        server.aggregate(client_states_subset, weights_subset)\n",
    "        accuracy_now = server.accuracy()\n",
    "        val_loss_now = server.val_loss(server.model, fed_avg_criterion())\n",
    "        test_loss_now = server.test_loss(fed_avg_criterion())\n",
    "        accuracy.append(accuracy_now)\n",
    "        val_loss.append(val_loss_now)\n",
    "        test_loss.append(test_loss_now)\n",
    "\n",
    "        log_dict = {\n",
    "            \"accuracy\": accuracy_now,\n",
    "            \"val_loss\": val_loss_now,\n",
    "            \"test_loss\": test_loss_now,\n",
    "        }\n",
    "        # wandb.log(log_dict)\n",
    "\n",
    "    # wandb.finish()\n",
    "    return accuracy, val_loss, test_loss, client_losses_init, client_losses_final\n",
    "\n",
    "\n",
    "def fed_prox_run(\n",
    "    clients,\n",
    "    server,\n",
    "    select_fraction,\n",
    "    T,\n",
    "    mu,\n",
    "    random_seed=0,\n",
    "    E=5,\n",
    "    B=10,\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.5,\n",
    "):\n",
    "    config = deepcopy(wandb_config)\n",
    "    config[\"algorithm\"] = \"FedProx\"\n",
    "    config[\"mu\"] = mu\n",
    "    wandb.init(project=\"federated-learning-summary\", config=config)\n",
    "\n",
    "    clients = deepcopy(clients)\n",
    "    server = deepcopy(server)\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    num_clients = len(clients)\n",
    "    num_selected = int(np.ceil(select_fraction * num_clients))\n",
    "\n",
    "    accuracy = []\n",
    "    val_loss = []\n",
    "    test_loss = []\n",
    "    for t in tqdm(range(T)):\n",
    "        # select clients to transmit weights to\n",
    "\n",
    "        # uniform random\n",
    "        all_clients = [i for i in range(num_clients)]\n",
    "        np.random.shuffle(all_clients)\n",
    "        selected_client_indices = all_clients[0:num_selected]\n",
    "        selected_status = [False for i in range(num_clients)]\n",
    "        for i in range(num_clients):\n",
    "            if i in selected_client_indices:\n",
    "                selected_status[i] = True\n",
    "\n",
    "        client_states = []\n",
    "        weights = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            if selected_status[idx]:\n",
    "                # perform descent at client\n",
    "                client_state = client.train(\n",
    "                    server.model,\n",
    "                    criterion=fed_prox_criterion(server.model, mu=mu),\n",
    "                    E=E,\n",
    "                    B=B,\n",
    "                    learning_rate=learning_rate,\n",
    "                    momentum=momentum,\n",
    "                )\n",
    "                weight = client.length  # number of data points at client\n",
    "                client_states.append(client_state)\n",
    "                weights.append(weight)\n",
    "\n",
    "        server.aggregate(client_states, weights)\n",
    "        accuracy_now = server.accuracy()\n",
    "        val_loss_now = server.val_loss(server.model, fed_avg_criterion())\n",
    "        test_loss_now = server.test_loss(fed_avg_criterion())\n",
    "        accuracy.append(accuracy_now)\n",
    "        val_loss.append(val_loss_now)\n",
    "        test_loss.append(test_loss_now)\n",
    "\n",
    "        log_dict = {\n",
    "            \"accuracy\": accuracy_now,\n",
    "            \"val_loss\": val_loss_now,\n",
    "            \"test_loss\": test_loss_now,\n",
    "        }\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return accuracy, val_loss, test_loss\n",
    "\n",
    "\n",
    "def power_of_choice_run(\n",
    "    clients,\n",
    "    server,\n",
    "    select_fraction,\n",
    "    T,\n",
    "    decay_factor=1,\n",
    "    random_seed=0,\n",
    "    E=5,\n",
    "    B=10,\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Power of Choice\n",
    "    decay_factor (default = 1, no decay)\n",
    "        determines the decay rate of number of clients to transmit the server model to (choose_from)\n",
    "    \"\"\"\n",
    "    config = deepcopy(wandb_config)\n",
    "    config[\"algorithm\"] = \"Power of Choice\"\n",
    "    config[\"decay_factor\"] = decay_factor\n",
    "    wandb.init(project=\"federated-learning-summary\", config=config)\n",
    "    clients = deepcopy(clients)\n",
    "    server = deepcopy(server)\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    num_clients = len(clients)\n",
    "    num_selected = int(np.ceil(select_fraction * num_clients))\n",
    "    choose_from = num_clients  # the size of initial client subset to query for loss\n",
    "\n",
    "    accuracy = []\n",
    "    val_loss = []\n",
    "    test_loss = []\n",
    "    for t in tqdm(range(T)):\n",
    "        # select clients to transmit weights to\n",
    "        if choose_from > num_selected:\n",
    "            choose_from *= decay_factor\n",
    "            choose_from = int(np.ceil(choose_from))\n",
    "        # uniform random\n",
    "        all_clients = [i for i in range(num_clients)]\n",
    "        np.random.shuffle(all_clients)\n",
    "        selected_client_indices = all_clients[0:choose_from]\n",
    "        selected_status = [False for i in range(num_clients)]\n",
    "        for i in range(num_clients):\n",
    "            if i in selected_client_indices:\n",
    "                selected_status[i] = True\n",
    "\n",
    "        client_losses = []  # will store array of size choose_from\n",
    "        for idx, client in enumerate(clients):\n",
    "            if selected_status[idx]:\n",
    "                # query selected clients for loss\n",
    "                client_loss = client.loss(server.model, fed_avg_criterion())\n",
    "                client_losses.append(client_loss)\n",
    "        # find indices of largest num_selected values in client_losses\n",
    "        indices = topk(client_losses, num_selected)\n",
    "        selected_client_indices_2 = []  # will store array of size num_selected\n",
    "        for i in indices:\n",
    "            selected_client_indices_2.append(selected_client_indices[i])\n",
    "\n",
    "        selected_status = [False for i in range(num_clients)]\n",
    "        for i in range(num_clients):\n",
    "            if i in selected_client_indices_2:\n",
    "                selected_status[i] = True\n",
    "\n",
    "        client_states = []\n",
    "        weights = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            if selected_status[idx]:\n",
    "                # perform descent at client\n",
    "                client_state = client.train(\n",
    "                    server.model,\n",
    "                    criterion=fed_avg_criterion(),\n",
    "                    E=E,\n",
    "                    B=B,\n",
    "                    learning_rate=learning_rate,\n",
    "                    momentum=momentum,\n",
    "                )\n",
    "                weight = client.length  # number of data points at client\n",
    "                client_states.append(client_state)\n",
    "                weights.append(weight)\n",
    "\n",
    "        server.aggregate(client_states, weights)\n",
    "        accuracy_now = server.accuracy()\n",
    "        val_loss_now = server.val_loss(server.model, fed_avg_criterion())\n",
    "        test_loss_now = server.test_loss(fed_avg_criterion())\n",
    "        accuracy.append(accuracy_now)\n",
    "        val_loss.append(val_loss_now)\n",
    "        test_loss.append(test_loss_now)\n",
    "\n",
    "        log_dict = {\n",
    "            \"accuracy\": accuracy_now,\n",
    "            \"val_loss\": val_loss_now,\n",
    "            \"test_loss\": test_loss_now,\n",
    "        }\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return accuracy, val_loss, test_loss\n",
    "\n",
    "\n",
    "def shapley_run(\n",
    "    clients,\n",
    "    server,\n",
    "    select_fraction,\n",
    "    T,\n",
    "    client_selection,\n",
    "    random_seed=0,\n",
    "    E=5,\n",
    "    B=10,\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.5,\n",
    "):\n",
    "    config = deepcopy(wandb_config)\n",
    "    config[\"client_selection\"] = client_selection\n",
    "    wandb.init(project=\"federated-learning-summary\", config=config)\n",
    "    clients = deepcopy(clients)\n",
    "    server = deepcopy(server)\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    num_clients = len(clients)\n",
    "    num_selected = int(np.ceil(select_fraction * num_clients))\n",
    "    choose_from = num_clients  # the size of initial client subset to query for loss\n",
    "\n",
    "    accuracy = []\n",
    "    val_loss = []\n",
    "    test_loss = []\n",
    "    shapley_values_T = []\n",
    "    selections_T = []\n",
    "    for t in tqdm(range(T)):\n",
    "        # select clients to transmit weights to\n",
    "        # uniform random\n",
    "        client_states = []\n",
    "        weights = []\n",
    "        client_losses = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            client_losses.append(client.loss(server.model, fed_avg_criterion()))\n",
    "            # perform descent at client\n",
    "            client_state = client.train(\n",
    "                server.model,\n",
    "                criterion=fed_avg_criterion(),\n",
    "                E=E,\n",
    "                B=B,\n",
    "                learning_rate=learning_rate,\n",
    "                momentum=momentum,\n",
    "            )\n",
    "            weight = client.length  # number of data points at client\n",
    "            client_states.append(client_state)\n",
    "            weights.append(weight)\n",
    "        # compute shapley values for each client\n",
    "        # shapley_values = server.shapley_values_mc(\n",
    "        #     fed_avg_criterion(), client_states, weights\n",
    "        # )\n",
    "        # shapley_values = server.shapley_values_tmc(\n",
    "        #     fed_avg_criterion(), client_states, weights\n",
    "        # )\n",
    "        shapley_values = server.shapley_values_true(\n",
    "            fed_avg_criterion(), client_states, weights\n",
    "        )\n",
    "        shapley_values_T.append(shapley_values)\n",
    "\n",
    "        # find indices of largest num_selected values in shapley_values\n",
    "        selections = [0 for i in range(num_clients)]\n",
    "        if client_selection == \"best\":\n",
    "            indices = topk(shapley_values, num_selected)\n",
    "        elif client_selection == \"fedavg\":\n",
    "            indices = np.random.choice(num_clients, size=num_selected, replace=False)\n",
    "        elif client_selection == \"worst\":\n",
    "            indices = np.argpartition(shapley_values, num_selected)[:num_selected]\n",
    "        elif client_selection == \"power_of_choice\":\n",
    "            indices = topk(client_losses, num_selected)\n",
    "        client_states_chosen = [client_states[i] for i in indices]\n",
    "        weights_chosen = [weights[i] for i in indices]\n",
    "\n",
    "        for idx in indices:\n",
    "            selections[idx] = 1\n",
    "        selections_T.append(selections)\n",
    "\n",
    "        server.aggregate(client_states_chosen, weights_chosen)\n",
    "        accuracy_now = server.accuracy()\n",
    "        val_loss_now = server.val_loss(server.model, fed_avg_criterion())\n",
    "        test_loss_now = server.test_loss(fed_avg_criterion())\n",
    "        accuracy.append(accuracy_now)\n",
    "        val_loss.append(val_loss_now)\n",
    "        test_loss.append(test_loss_now)\n",
    "\n",
    "        log_dict = {\n",
    "            \"accuracy\": accuracy_now,\n",
    "            \"val_loss\": val_loss_now,\n",
    "            \"test_loss\": test_loss_now,\n",
    "        }\n",
    "        for i in range(num_clients):\n",
    "            log_dict[f\"shapley_value_{i}\"] = shapley_values[i]\n",
    "            log_dict[f\"selection_{i}\"] = selections[i]\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    wandb.finish()\n",
    "    return accuracy, val_loss, test_loss, shapley_values_T, selections_T\n",
    "\n",
    "\n",
    "def ucb_run(\n",
    "    clients,\n",
    "    server,\n",
    "    select_fraction,\n",
    "    T,\n",
    "    beta,\n",
    "    random_seed=0,\n",
    "    E=5,\n",
    "    B=10,\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.5,\n",
    "):\n",
    "    config = deepcopy(wandb_config)\n",
    "    config[\"client_selection\"] = \"ucb\"\n",
    "    config[\"beta\"] = beta\n",
    "    wandb.init(project=\"federated-learning-summary\", config=config)\n",
    "    clients = deepcopy(clients)\n",
    "    server = deepcopy(server)\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    num_clients = len(clients)\n",
    "    num_selected = int(np.ceil(select_fraction * num_clients))\n",
    "\n",
    "    accuracy = []\n",
    "    val_loss = []\n",
    "    test_loss = []\n",
    "    shapley_values_T = []\n",
    "    selections_T = []\n",
    "    draws_T = []\n",
    "\n",
    "    N_t = [0 for i in range(num_clients)]\n",
    "    UCB = [0 for i in range(num_clients)]\n",
    "    SV = [0 for i in range(num_clients)]\n",
    "    for t in tqdm(range(T)):\n",
    "        # select clients to transmit weights to\n",
    "        # initially sample every client atleast once\n",
    "        selected_status = [False for i in range(num_clients)]\n",
    "        if t < np.floor(num_clients / num_selected):\n",
    "            for idx in range(t * num_selected, (t + 1) * num_selected):\n",
    "                selected_status[idx] = True\n",
    "                N_t[idx] += 1\n",
    "        elif t == np.floor(num_clients / num_selected):\n",
    "            for idx in range(t * num_selected, num_clients):\n",
    "                selected_status[idx] = True\n",
    "                N_t[idx] += 1\n",
    "            remaining_selections = num_selected * (t + 1) - num_clients\n",
    "            if remaining_selections > 0:\n",
    "                unselected_indices = list(range(0, t * num_selected))\n",
    "                selected_indices_subset = np.random.choice(\n",
    "                    unselected_indices, size=remaining_selections, replace=False\n",
    "                )\n",
    "                for idx in selected_indices_subset:\n",
    "                    selected_status[idx] = True\n",
    "                    N_t[idx] += 1\n",
    "        else:\n",
    "            # do UCB selection\n",
    "            selected_indices = topk(UCB, num_selected)\n",
    "            for idx in selected_indices:\n",
    "                selected_status[idx] = True\n",
    "                N_t[idx] += 1\n",
    "        # uniform random\n",
    "        client_states = []\n",
    "        weights = []\n",
    "\n",
    "        for idx, client in enumerate(clients):\n",
    "            if selected_status[idx]:\n",
    "                # perform descent at client\n",
    "                client_state = client.train(\n",
    "                    server.model,\n",
    "                    criterion=fed_avg_criterion(),\n",
    "                    E=E,\n",
    "                    B=B,\n",
    "                    learning_rate=learning_rate,\n",
    "                    momentum=momentum,\n",
    "                )\n",
    "                weight = client.length  # number of data points at client\n",
    "                client_states.append(client_state)\n",
    "                weights.append(weight)\n",
    "\n",
    "        # compute shapley values for each client BEFORE updating server model\n",
    "        # shapley_values = server.shapley_values_mc(\n",
    "        #     fed_avg_criterion(), client_states, weights\n",
    "        # )\n",
    "        # shapley_values = server.shapley_values_tmc(\n",
    "        #     fed_avg_criterion(), client_states, weights\n",
    "        # )\n",
    "        shapley_values = server.shapley_values_true(\n",
    "            fed_avg_criterion(), client_states, weights\n",
    "        )\n",
    "        # update server model\n",
    "        server.aggregate(client_states, weights)\n",
    "        accuracy_now = server.accuracy()\n",
    "        val_loss_now = server.val_loss(server.model, fed_avg_criterion())\n",
    "        test_loss_now = server.test_loss(fed_avg_criterion())\n",
    "        accuracy.append(accuracy_now)\n",
    "        val_loss.append(val_loss_now)\n",
    "        test_loss.append(test_loss_now)\n",
    "\n",
    "        log_dict = {\n",
    "            \"accuracy\": accuracy_now,\n",
    "            \"val_loss\": val_loss_now,\n",
    "            \"test_loss\": test_loss_now,\n",
    "        }\n",
    "\n",
    "        # compute UCB for next round of selections\n",
    "        selections = [0 for i in range(num_clients)]\n",
    "        counter = 0\n",
    "        for i in range(num_clients):\n",
    "            if selected_status[i]:\n",
    "                SV[i] = ((N_t[i] - 1) * SV[i] + shapley_values[counter]) / N_t[i]\n",
    "                counter += 1\n",
    "                selections[i] = 1\n",
    "            UCB[i] = SV[i] + beta * np.sqrt(np.log(t + 1) / N_t[i])\n",
    "        shapley_values_T.append(deepcopy(SV))\n",
    "        selections_T.append(deepcopy(selections))\n",
    "        draws_T.append(deepcopy(N_t))\n",
    "\n",
    "        for i in range(num_clients):\n",
    "            log_dict[f\"shapley_value_{i}\"] = SV[i]\n",
    "            log_dict[f\"selection_{i}\"] = selections[i]\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    wandb.finish()\n",
    "    return accuracy, val_loss, test_loss, shapley_values_T, selections_T, draws_T\n",
    "\n",
    "\n",
    "def sfedavg_run(\n",
    "    clients,\n",
    "    server,\n",
    "    select_fraction,\n",
    "    T,\n",
    "    alpha,\n",
    "    beta,\n",
    "    random_seed=0,\n",
    "    E=5,\n",
    "    B=10,\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.5,\n",
    "):\n",
    "    config = deepcopy(wandb_config)\n",
    "    config[\"client_selection\"] = \"S-FedAvg\"\n",
    "    config[\"algo-alpha\"] = alpha\n",
    "    config[\"algo-beta\"] = beta\n",
    "    wandb.init(project=\"federated-learning-summary\", config=config)\n",
    "    clients = deepcopy(clients)\n",
    "    server = deepcopy(server)\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    num_clients = len(clients)\n",
    "    num_selected = int(np.ceil(select_fraction * num_clients))\n",
    "\n",
    "    accuracy = []\n",
    "    val_loss = []\n",
    "    test_loss = []\n",
    "    shapley_values_T = []\n",
    "    selections_T = []\n",
    "    Phi_T = []\n",
    "    draws_T = []\n",
    "\n",
    "    N_t = [0 for i in range(num_clients)]\n",
    "    Phi = [1 / (num_clients) for i in range(num_clients)]\n",
    "    SV = [0 for i in range(num_clients)]\n",
    "    for t in tqdm(range(T)):\n",
    "        # select clients to transmit weights to\n",
    "        # initially sample every client atleast once\n",
    "        selected_status = [False for i in range(num_clients)]\n",
    "        # do Game of Gradients Selection\n",
    "        all_indices = list(range(num_clients))\n",
    "        probs = np.exp(np.array(Phi))\n",
    "        probs = probs / np.sum(probs)\n",
    "        selected_indices = np.random.choice(\n",
    "            all_indices, size=num_selected, replace=False, p=probs\n",
    "        )\n",
    "        for idx in selected_indices:\n",
    "            selected_status[idx] = True\n",
    "            N_t[idx] += 1\n",
    "        # uniform random\n",
    "        client_states = []\n",
    "        weights = []\n",
    "\n",
    "        for idx, client in enumerate(clients):\n",
    "            if selected_status[idx]:\n",
    "                # perform descent at client\n",
    "                client_state = client.train(\n",
    "                    server.model,\n",
    "                    criterion=fed_avg_criterion(),\n",
    "                    E=E,\n",
    "                    B=B,\n",
    "                    learning_rate=learning_rate,\n",
    "                    momentum=momentum,\n",
    "                )\n",
    "                weight = client.length  # number of data points at client\n",
    "                weight /= probs[idx]  # for unbiased averaging\n",
    "                client_states.append(client_state)\n",
    "                weights.append(weight)\n",
    "\n",
    "        # compute shapley values for each client BEFORE updating server model\n",
    "        # shapley_values = server.shapley_values_mc(\n",
    "        #     fed_avg_criterion(), client_states, weights\n",
    "        # )\n",
    "        # shapley_values = server.shapley_values_tmc(\n",
    "        #     fed_avg_criterion(), client_states, weights\n",
    "        # )\n",
    "        shapley_values = server.shapley_values_true(\n",
    "            fed_avg_criterion(), client_states, weights\n",
    "        )\n",
    "        # update server model\n",
    "        server.aggregate(client_states, weights)\n",
    "        accuracy_now = server.accuracy()\n",
    "        val_loss_now = server.val_loss(server.model, fed_avg_criterion())\n",
    "        test_loss_now = server.test_loss(fed_avg_criterion())\n",
    "        accuracy.append(accuracy_now)\n",
    "        val_loss.append(val_loss_now)\n",
    "        test_loss.append(test_loss_now)\n",
    "\n",
    "        log_dict = {\n",
    "            \"accuracy\": accuracy_now,\n",
    "            \"val_loss\": val_loss_now,\n",
    "            \"test_loss\": test_loss_now,\n",
    "        }\n",
    "\n",
    "        # compute Phi for next round of selections\n",
    "        selections = [0 for i in range(num_clients)]\n",
    "        counter = 0\n",
    "        # defined as function parameters now\n",
    "        # alpha = 0.75\n",
    "        # beta = 0.25\n",
    "        for i in range(num_clients):\n",
    "            if selected_status[i]:\n",
    "                SV[i] = ((N_t[i] - 1) * SV[i] + shapley_values[counter]) / N_t[i]\n",
    "                counter += 1\n",
    "                selections[i] = 1\n",
    "                Phi[i] = alpha * Phi[i] + beta * SV[i]\n",
    "        shapley_values_T.append(deepcopy(SV))\n",
    "        Phi_T.append(deepcopy(Phi))\n",
    "        selections_T.append(deepcopy(selections))\n",
    "        draws_T.append(deepcopy(N_t))\n",
    "\n",
    "        for i in range(num_clients):\n",
    "            log_dict[f\"shapley_value_{i}\"] = SV[i]\n",
    "            log_dict[f\"selection_{i}\"] = selections[i]\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    wandb.finish()\n",
    "    return accuracy, val_loss, test_loss, shapley_values_T, Phi_T, selections_T, draws_T\n",
    "\n",
    "\n",
    "def ucb_runs(beta, runs):\n",
    "    avg_accuracy_list = []\n",
    "    for run in range(runs):\n",
    "        accuracy_list, *_ = ucb_run(\n",
    "            deepcopy(clients),\n",
    "            deepcopy(server),\n",
    "            select_fraction,\n",
    "            T,\n",
    "            beta=beta,\n",
    "            random_seed=run,\n",
    "        )\n",
    "        accuracy_list = np.array(accuracy_list)\n",
    "        if run == 0:\n",
    "            avg_accuracy_list = deepcopy(accuracy_list)\n",
    "        avg_accuracy_list = (run * avg_accuracy_list + accuracy_list) / (run + 1)\n",
    "    return avg_accuracy_list\n",
    "\n",
    "\n",
    "def sfedavg_runs(alpha, beta, runs):\n",
    "    avg_accuracy_list = []\n",
    "    for run in range(runs):\n",
    "        accuracy_list, *_ = sfedavg_run(\n",
    "            deepcopy(clients),\n",
    "            deepcopy(server),\n",
    "            select_fraction,\n",
    "            T,\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "            random_seed=run,\n",
    "        )\n",
    "\n",
    "        accuracy_list = np.array(accuracy_list)\n",
    "        if run == 0:\n",
    "            avg_accuracy_list = deepcopy(accuracy_list)\n",
    "        avg_accuracy_list = (run * avg_accuracy_list + accuracy_list) / (run + 1)\n",
    "    return avg_accuracy_list\n",
    "\n",
    "\n",
    "def fedavg_runs(runs):\n",
    "    avg_accuracy_list = []\n",
    "    for run in range(runs):\n",
    "        accuracy_list, *_ = fed_avg_run(\n",
    "            deepcopy(clients),\n",
    "            deepcopy(server),\n",
    "            select_fraction,\n",
    "            T,\n",
    "            random_seed=run,\n",
    "        )\n",
    "        accuracy_list = np.array(accuracy_list)\n",
    "        if run == 0:\n",
    "            avg_accuracy_list = deepcopy(accuracy_list)\n",
    "        avg_accuracy_list = (run * avg_accuracy_list + accuracy_list) / (run + 1)\n",
    "    return avg_accuracy_list\n",
    "\n",
    "\n",
    "def poc_runs(decay_factor, runs):\n",
    "    avg_accuracy_list = []\n",
    "    for run in range(runs):\n",
    "        accuracy_list, *_ = power_of_choice_run(\n",
    "            deepcopy(clients),\n",
    "            deepcopy(server),\n",
    "            select_fraction,\n",
    "            T,\n",
    "            decay_factor=decay_factor,\n",
    "            random_seed=random_seed,\n",
    "        )\n",
    "        accuracy_list = np.array(accuracy_list)\n",
    "        if run == 0:\n",
    "            avg_accuracy_list = deepcopy(accuracy_list)\n",
    "        avg_accuracy_list = (run * avg_accuracy_list + accuracy_list) / (run + 1)\n",
    "    return avg_accuracy_list\n",
    "\n",
    "\n",
    "def fedprox_runs(mu, runs):\n",
    "    avg_accuracy_list = []\n",
    "    for run in range(runs):\n",
    "        accuracy_list, *_ = fed_prox_run(\n",
    "            deepcopy(clients),\n",
    "            deepcopy(server),\n",
    "            select_fraction,\n",
    "            T,\n",
    "            mu=mu,\n",
    "            random_seed=random_seed,\n",
    "        )\n",
    "        accuracy_list = np.array(accuracy_list)\n",
    "        if run == 0:\n",
    "            avg_accuracy_list = deepcopy(accuracy_list)\n",
    "        avg_accuracy_list = (run * avg_accuracy_list + accuracy_list) / (run + 1)\n",
    "    return avg_accuracy_list\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# Hyperparameter search starts here\n",
    "# \"\"\"\n",
    "\n",
    "# dirichlet_alpha = alpha\n",
    "# synthetic_alpha = alpha\n",
    "# synthetic_beta = beta\n",
    "\n",
    "# # UCB search\n",
    "\n",
    "# beta_vals = [1e-1, 1, 1e1, 1e2]\n",
    "# accuracies_ucb = {}\n",
    "# for beta in beta_vals:\n",
    "#     accuracies_ucb[beta] = ucb_runs(beta, 3)\n",
    "\n",
    "# method = \"ucb\"\n",
    "# accuracies_summary = accuracies_ucb\n",
    "\n",
    "# if dataset in [\"mnist\", \"cifar10\"]:\n",
    "#     with open(\n",
    "#         f\"./results/{method}_{dataset}_{num_clients}_{random_seed}_{dirichlet_alpha}.pickle\",\n",
    "#         \"wb\",\n",
    "#     ) as f:\n",
    "#         pickle.dump(accuracies_summary, f)\n",
    "# else:\n",
    "#     with open(\n",
    "#         f\"./results/{method}_{dataset}_{num_clients}_{random_seed}_{synthetic_alpha}_{synthetic_beta}.pickle\",\n",
    "#         \"wb\",\n",
    "#     ) as f:\n",
    "#         pickle.dump(accuracies_summary, f)\n",
    "\n",
    "\n",
    "# # S-FedAvg search\n",
    "\n",
    "# alpha_vals = np.arange(0.1, 1, 0.2)\n",
    "# beta_vals = np.arange(0.1, 1, 0.2)\n",
    "# accuracies_sfedavg = {}\n",
    "# for alpha in alpha_vals:\n",
    "#     beta = 1 - alpha\n",
    "#     accuracies_sfedavg[(alpha, beta)] = sfedavg_runs(alpha, beta, 3)\n",
    "\n",
    "# method = \"sfedavg\"\n",
    "# accuracies_summary = accuracies_sfedavg\n",
    "\n",
    "# if dataset in [\"mnist\", \"cifar10\"]:\n",
    "#     with open(\n",
    "#         f\"./results/{method}_{dataset}_{num_clients}_{random_seed}_{dirichlet_alpha}.pickle\",\n",
    "#         \"wb\",\n",
    "#     ) as f:\n",
    "#         pickle.dump(accuracies_summary, f)\n",
    "# else:\n",
    "#     with open(\n",
    "#         f\"./results/{method}_{dataset}_{num_clients}_{random_seed}_{synthetic_alpha}_{synthetic_beta}.pickle\",\n",
    "#         \"wb\",\n",
    "#     ) as f:\n",
    "#         pickle.dump(accuracies_summary, f)\n",
    "\n",
    "# # FedAvg\n",
    "\n",
    "# accuracies_fedavg = fedavg_runs(5)\n",
    "# method = \"fedavg\"\n",
    "# accuracies_summary = accuracies_fedavg\n",
    "\n",
    "# if dataset in [\"mnist\", \"cifar10\"]:\n",
    "#     with open(\n",
    "#         f\"./results/{method}_{dataset}_{num_clients}_{random_seed}_{dirichlet_alpha}.pickle\",\n",
    "#         \"wb\",\n",
    "#     ) as f:\n",
    "#         pickle.dump(accuracies_summary, f)\n",
    "# else:\n",
    "#     with open(\n",
    "#         f\"./results/{method}_{dataset}_{num_clients}_{random_seed}_{synthetic_alpha}_{synthetic_beta}.pickle\",\n",
    "#         \"wb\",\n",
    "#     ) as f:\n",
    "#         pickle.dump(accuracies_summary, f)\n",
    "\n",
    "# # Power-of-Choice\n",
    "\n",
    "# decay_factors = [1, 0.99, 0.95, 0.9, 0.8]\n",
    "# accuracies_poc = {}\n",
    "# for decay_factor in decay_factors:\n",
    "#     accuracies_poc[decay_factor] = poc_runs(decay_factor, 3)\n",
    "\n",
    "# method = \"poc\"\n",
    "# accuracies_summary = accuracies_poc\n",
    "\n",
    "# if dataset in [\"mnist\", \"cifar10\"]:\n",
    "#     with open(\n",
    "#         f\"./results/{method}_{dataset}_{num_clients}_{random_seed}_{dirichlet_alpha}.pickle\",\n",
    "#         \"wb\",\n",
    "#     ) as f:\n",
    "#         pickle.dump(accuracies_summary, f)\n",
    "# else:\n",
    "#     with open(\n",
    "#         f\"./results/{method}_{dataset}_{num_clients}_{random_seed}_{synthetic_alpha}_{synthetic_beta}.pickle\",\n",
    "#         \"wb\",\n",
    "#     ) as f:\n",
    "#         pickle.dump(accuracies_summary, f)\n",
    "\n",
    "# # FedProx\n",
    "\n",
    "# mu_vals = [10**i for i in range(-3, 3)]\n",
    "# accuracies_fedprox = {}\n",
    "# for mu in mu_vals:\n",
    "#     accuracies_fedprox[mu] = fedprox_runs(mu, 3)\n",
    "\n",
    "# method = \"fedprox\"\n",
    "# accuracies_summary = accuracies_fedprox\n",
    "\n",
    "# if dataset in [\"mnist\", \"cifar10\"]:\n",
    "#     with open(\n",
    "#         f\"./results/{method}_{dataset}_{num_clients}_{random_seed}_{dirichlet_alpha}.pickle\",\n",
    "#         \"wb\",\n",
    "#     ) as f:\n",
    "#         pickle.dump(accuracies_summary, f)\n",
    "# else:\n",
    "#     with open(\n",
    "#         f\"./results/{method}_{dataset}_{num_clients}_{random_seed}_{synthetic_alpha}_{synthetic_beta}.pickle\",\n",
    "#         \"wb\",\n",
    "#     ) as f:\n",
    "#         pickle.dump(accuracies_summary, f)\n",
    "\n",
    "\n",
    "# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# Hyperparameter search ends here\n",
    "# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "\n",
    "# sns.heatmap(draws_heatmap).set(title=\"draws\")\n",
    "# plt.show()\n",
    "# sns.heatmap(shapley_heatmap).set(title=\"shapley values\")\n",
    "# plt.show()\n",
    "# sns.heatmap(selection_heatmap).set(title=\"selections\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(accuracy_ucb, label=\"UCB\")\n",
    "# plt.plot(accuracy_fedavg, label=\"fedavg\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(5):\n",
    "#     accuracy_poc, _, _ = power_of_choice_run(\n",
    "#         deepcopy(clients),\n",
    "#         deepcopy(server),\n",
    "#         select_fraction,\n",
    "#         T,\n",
    "#         decay_factor=0.95,\n",
    "#         random_seed=i,\n",
    "#     )\n",
    "\n",
    "#     accuracy_poc_nodecay, _, _ = power_of_choice_run(\n",
    "#         deepcopy(clients),\n",
    "#         deepcopy(server),\n",
    "#         select_fraction,\n",
    "#         T,\n",
    "#         decay_factor=1,\n",
    "#         random_seed=i,\n",
    "#     )\n",
    "\n",
    "(\n",
    "    accuracy,\n",
    "    val_loss,\n",
    "    test_loss,\n",
    "    client_losses_init,\n",
    "    client_losses_final,\n",
    ") = fed_avg_run_analysis(\n",
    "    deepcopy(clients), deepcopy(server), select_fraction, T, random_seed=1\n",
    ")\n",
    "\n",
    "#     accuracy_prox, _, _ = fed_prox_run(\n",
    "#         deepcopy(clients), deepcopy(server), select_fraction, T, mu=0.1, random_seed=i\n",
    "#     )\n",
    "#     if i == 0:\n",
    "#         accuracy_avg = np.array(accuracy)\n",
    "#         accuracy_prox_avg = np.array(accuracy_prox)\n",
    "#         accuracy_poc_avg = np.array(accuracy_poc)\n",
    "#         accuracy_poc_nodecay_avg = np.array(accuracy_poc_nodecay)\n",
    "#     else:\n",
    "#         accuracy_avg = accuracy_avg * (i / (i + 1)) + np.array(accuracy) * (1 / (i + 1))\n",
    "#         accuracy_prox_avg = accuracy_prox_avg * (i / (i + 1)) + np.array(\n",
    "#             accuracy_prox\n",
    "#         ) * (1 / (i + 1))\n",
    "#         accuracy_poc_avg = accuracy_poc_avg * (i / (i + 1)) + np.array(accuracy_poc) * (\n",
    "#             1 / (i + 1)\n",
    "#         )\n",
    "#         accuracy_poc_nodecay_avg = accuracy_poc_nodecay_avg * (i / (i + 1)) + np.array(\n",
    "#             accuracy_poc_nodecay\n",
    "#         ) * (1 / (i + 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x186b7ebbf40>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 10\n",
    "plt.plot(client_losses_init[i], label = 'init')\n",
    "plt.plot(client_losses_final[i], label = 'final')\n",
    "plt.ylim((0,5))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_loss, label=\"val loss\")\n",
    "plt.plot(test_loss, label=\"test loss\")\n",
    "for i in range(num_clients):\n",
    "    plt.plot(client_losses_init[i], label=f\"client loss init {i}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
